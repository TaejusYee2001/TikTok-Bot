{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "import time\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions for read/write html\n",
    "def read_html(path): \n",
    "    with open(path, 'rb') as f: \n",
    "        return f.read()\n",
    "\n",
    "def write_html(html, path):\n",
    "    directory = os.path.dirname(path)\n",
    "    if not os.path.exists(directory): \n",
    "        os.makedirs(directory)\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make website cache many posts by scrolling and save html content afterwards\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://www.reddit.com/r/AmItheAsshole/'\n",
    "driver.get(url)\n",
    "\n",
    "SCROLL_PAUSE_TIME = random.uniform(2, 5)\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "num_scrolls = 0\n",
    "while (num_scrolls < 5):\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(SCROLL_PAUSE_TIME + random.uniform(0.5, 1.5))\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "    num_scrolls += 1\n",
    "    \n",
    "    # Random mouse movement to simulate human behavior\n",
    "    action = ActionChains(driver)\n",
    "    action.move_by_offset(random.randint(0, 100), random.randint(0, 100)).perform()\n",
    "    \n",
    "raw_html_path = 'data/aita-reddit-html.txt'\n",
    "directory = os.path.dirname(raw_html_path)\n",
    "\n",
    "if not os.path.exists(directory): \n",
    "    os.makedirs(directory)\n",
    "    \n",
    "with open(raw_html_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(driver.page_source)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles found: 50\n"
     ]
    }
   ],
   "source": [
    "# Parse webpage HTML and get links to each article\n",
    "with open(raw_html_path, 'r', encoding='utf-8') as file:\n",
    "    raw_html = file.read()\n",
    "\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "articles = soup.find_all('article', class_='w-full m-0')\n",
    "\n",
    "print(f\"Number of articles found: {len(articles)}\")\n",
    "\n",
    "links = []\n",
    "for article in articles: \n",
    "    shreddit_post = article.find('shreddit-post')\n",
    "    links.append(shreddit_post.get('content-href'))\n",
    "\n",
    "with open('data/reddit-links.txt', 'w', encoding='utf-8') as f: \n",
    "    for link in links:\n",
    "        f.write(link + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform new fetch on each post link\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"}\n",
    "for index, link in enumerate(links): \n",
    "     aita_post_req = requests.get(link, headers=headers)\n",
    "     file_path = f'data/posts-html/aita-post{index}-html.txt'\n",
    "     write_html(aita_post_req.content, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from HTML served from the post link\n",
    "posts_html_path = 'data/posts-html'\n",
    "posts_path = 'data/posts'\n",
    "allowed_chars = set(string.printable)\n",
    "\n",
    "if not os.path.exists(posts_path): \n",
    "    os.makedirs(posts_path)\n",
    "\n",
    "items = os.listdir(posts_html_path)\n",
    "for index, item in enumerate(items): \n",
    "    aita_post_soup = BeautifulSoup(read_html(posts_html_path + '/' + item), 'html.parser')\n",
    "    post_container = aita_post_soup.find('div', class_='text-neutral-content')\n",
    "    div1 = post_container.find('div')\n",
    "    div2 = div1.find('div')\n",
    "    p_elements = div2.find_all('p')\n",
    "    post_text = '\\n\\n'.join(p.get_text(strip=True) for p in p_elements) # Concatenate text\n",
    "    file_path = os.path.join(posts_path, f'aita-post{index}.txt')\n",
    "    with open(file_path, 'w', encoding='utf-8') as f: \n",
    "        post_text = ''.join(filter(lambda x: x in allowed_chars, post_text))\n",
    "        f.write(post_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text To Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create audio file from text\n",
    "def textToSpeech(text, output_file): \n",
    "    tts = gTTS(text=text, lang='en', slow=False)\n",
    "    tts.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "gTTSError",
     "evalue": "429 (Too Many Requests) from TTS API. Probable cause: Unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\taeju\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gtts\\tts.py:279\u001b[0m, in \u001b[0;36mgTTS.stream\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, idx, r\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m--> 279\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Request successful, bad response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\taeju\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:960\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://translate.google.com/_/TranslateWebserverUi/data/batchexecute&q=EgSuoK41GLa31LMGIjDSOcfhGZKXfPlFMJ3EaPMqqW8jrNMepETRzFFZtAkqc5iQysePBXlr8UuO88UNR1EyAXJaAUM",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mgTTSError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[0;32m      9\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtextToSpeech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost-audio\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mindex\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mtextToSpeech\u001b[1;34m(text, output_file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtextToSpeech\u001b[39m(text, output_file): \n\u001b[0;32m      3\u001b[0m     tts \u001b[38;5;241m=\u001b[39m gTTS(text\u001b[38;5;241m=\u001b[39mtext, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, slow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taeju\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gtts\\tts.py:335\u001b[0m, in \u001b[0;36mgTTS.save\u001b[1;34m(self, savefile)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the TTS API request and write result to file.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(savefile), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_to_fp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    337\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, savefile)\n",
      "File \u001b[1;32mc:\\Users\\taeju\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gtts\\tts.py:316\u001b[0m, in \u001b[0;36mgTTS.write_to_fp\u001b[1;34m(self, fp)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the TTS API request(s) and write bytes to a file-like object.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, decoded \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream()):\n\u001b[0;32m    317\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(decoded)\n\u001b[0;32m    318\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m written to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, idx, fp)\n",
      "File \u001b[1;32mc:\\Users\\taeju\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gtts\\tts.py:283\u001b[0m, in \u001b[0;36mgTTS.stream\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Request successful, bad response\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m gTTSError(tts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, response\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Request failed\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[1;31mgTTSError\u001b[0m: 429 (Too Many Requests) from TTS API. Probable cause: Unknown"
     ]
    }
   ],
   "source": [
    "# Read text from data/posts directory and save audio files in audio directory\n",
    "audio_dir = 'output/audio'\n",
    "if not os.path.exists(audio_dir): \n",
    "    os.makedirs(audio_dir)\n",
    "    \n",
    "for index, filename in enumerate(os.listdir(posts_path)): \n",
    "    path = os.path.join(posts_path, filename)\n",
    "    with open(path, 'r') as file: \n",
    "        text = file.read()\n",
    "        \n",
    "    textToSpeech(text, os.path.join(audio_dir, f'post-audio{index}.mp3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Subtitle Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import whisper\n",
    "import ffmpeg\n",
    "import subprocess\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aligned subtitles from audio file\n",
    "model = whisper.load_model('base')\n",
    "audio_file_path = 'output/audio/post-audio9.mp3'\n",
    "\n",
    "result = model.transcribe(audio_file_path)\n",
    "print(result[\"segments\"])\n",
    "for segment in result['segments']: \n",
    "    print(segment)\n",
    "    \n",
    "#options = whisper.DecodingOptions(fp16=False)\n",
    "#decoded_result = whisper.decode(model, result['audio'], options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = 'output/audio/post-audio9.mp3'\n",
    "video_file_path = 'output/video/post-video9.mp4'\n",
    "\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    '-f', 'lavfi',\n",
    "    '-i', 'color=size=1280x720:duration=30:rate=30:color=black',\n",
    "    '-i', audio_file_path,\n",
    "    '-c:v', 'libx264',\n",
    "    '-tune', 'stillimage',\n",
    "    '-c:a', 'aac',\n",
    "    '-b:a', '192k',\n",
    "    '-pix_fmt', 'yuv420p',\n",
    "    '-shortest',\n",
    "    video_file_path\n",
    "]\n",
    "\n",
    "subprocess.run(ffmpeg_command, check=True)\n",
    "\n",
    "print(\"saved video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio extracted to output/audio/extracted-audio.mp3\n"
     ]
    }
   ],
   "source": [
    "video_file = 'output/video/post-video9.mp4'\n",
    "audio_output = 'output/audio/extracted-audio.mp3'\n",
    "subtitles_file = 'output/subtitles/subtitles.srt'  # Assume this file is generated\n",
    "output_video_file = 'output/video/post-video9-subtitled.mp4'\n",
    "\n",
    "# Ensure the output directories exist\n",
    "os.makedirs(os.path.dirname(audio_output), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(subtitles_file), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(output_video_file), exist_ok=True)\n",
    "\n",
    "# Extract audio from the video\n",
    "extract_audio_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_file,\n",
    "    '-q:a', '0',\n",
    "    '-map', 'a',\n",
    "    audio_output\n",
    "]\n",
    "\n",
    "# Run the FFmpeg commands\n",
    "try:\n",
    "    # Extract audio\n",
    "    subprocess.run(extract_audio_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(f\"Audio extracted to {audio_output}\")\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Command output: {e.output}\")\n",
    "    print(f\"Stderr: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 294981 KiB | 723231 KiB |  43224 MiB |  42935 MiB |\n",
      "|       from large pool | 218732 KiB | 533001 KiB |  37547 MiB |  37334 MiB |\n",
      "|       from small pool |  76249 KiB | 190230 KiB |   5676 MiB |   5601 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 294981 KiB | 723231 KiB |  43224 MiB |  42935 MiB |\n",
      "|       from large pool | 218732 KiB | 533001 KiB |  37547 MiB |  37334 MiB |\n",
      "|       from small pool |  76249 KiB | 190230 KiB |   5676 MiB |   5601 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 292674 KiB | 718813 KiB |  43042 MiB |  42757 MiB |\n",
      "|       from large pool | 216426 KiB | 528585 KiB |  37375 MiB |  37164 MiB |\n",
      "|       from small pool |  76248 KiB | 190228 KiB |   5667 MiB |   5592 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   | 331776 KiB |    794 MiB |   1392 MiB |   1068 MiB |\n",
      "|       from large pool | 247808 KiB |    606 MiB |   1062 MiB |    820 MiB |\n",
      "|       from small pool |  83968 KiB |    188 MiB |    330 MiB |    248 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  36795 KiB |  79517 KiB |  23935 MiB |  23899 MiB |\n",
      "|       from large pool |  29076 KiB |  72303 KiB |  18092 MiB |  18063 MiB |\n",
      "|       from small pool |   7719 KiB |   8779 KiB |   5843 MiB |   5836 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     249    |     742    |   94906    |   94657    |\n",
      "|       from large pool |      28    |      82    |    6687    |    6659    |\n",
      "|       from small pool |     221    |     660    |   88219    |   87998    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     249    |     742    |   94906    |   94657    |\n",
      "|       from large pool |      28    |      82    |    6687    |    6659    |\n",
      "|       from small pool |     221    |     660    |   88219    |   87998    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      49    |     112    |     196    |     147    |\n",
      "|       from large pool |       8    |      18    |      31    |      23    |\n",
      "|       from small pool |      41    |      94    |     165    |     124    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      12    |      21    |   35672    |   35660    |\n",
      "|       from large pool |       5    |      11    |    1349    |    1344    |\n",
      "|       from small pool |       7    |      17    |   34323    |   34316    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Subtitles have been saved as output/subtitles/subtitles.srt\n"
     ]
    }
   ],
   "source": [
    "audio_output = 'output/audio/extracted-audio.mp3'\n",
    "subtitles_file = 'output/subtitles/subtitles.srt'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "\n",
    "model = whisper.load_model('base')\n",
    "\n",
    "# Transcribe the audio file\n",
    "result = model.transcribe(word_timestamps=True, audio=audio_output)\n",
    "\n",
    "# Function to convert seconds to SRT time format\n",
    "def seconds_to_srt_time(seconds):\n",
    "    millisec = int((seconds - int(seconds)) * 1000)\n",
    "    time_str = f\"{int(seconds // 3600):02}:{int((seconds % 3600) // 60):02}:{int(seconds % 60):02},{millisec:03}\"\n",
    "    return time_str\n",
    "\n",
    "# Create the SRT content\n",
    "srt_content = \"\"\n",
    "counter = 1\n",
    "\n",
    "for segment in result['segments']:\n",
    "    for word in segment['words']: \n",
    "        start_time = seconds_to_srt_time(segment['start'])\n",
    "        end_time = seconds_to_srt_time(segment['end'])\n",
    "        text = word['word']\n",
    "        srt_content += f\"{counter}\\n{start_time} --> {end_time}\\n{text.strip()}\\n\\n\"\n",
    "        counter += 1\n",
    "\n",
    "# Write the SRT content to a file\n",
    "with open(subtitles_file, 'w', encoding='utf-8') as srt_file:\n",
    "    srt_file.write(srt_content)\n",
    "\n",
    "print(f\"Subtitles have been saved as {subtitles_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtitled video created at output/video/post-video9-subtitled.mp4\n",
      "\n",
      "ffmpeg version 7.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output/video/post-video9.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:30.00, start: 0.000000, bitrate: 108 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], 10 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 91 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "[Parsed_subtitles_0 @ 000001caedff00c0] libass API version: 0x1702000\n",
      "[Parsed_subtitles_0 @ 000001caedff00c0] libass source: commit: 0.17.2-6-g85ff2b3c5586747002b6d219bd316a68b2fec801\n",
      "[Parsed_subtitles_0 @ 000001caedff00c0] Shaper: FriBidi 1.0.14 (SIMPLE) HarfBuzz-ng 8.5.0 (COMPLEX)\n",
      "[Parsed_subtitles_0 @ 000001caedff00c0] Using font provider directwrite (with GDI)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[Parsed_subtitles_0 @ 000001caedd8b540] libass API version: 0x1702000\n",
      "[Parsed_subtitles_0 @ 000001caedd8b540] libass source: commit: 0.17.2-6-g85ff2b3c5586747002b6d219bd316a68b2fec801\n",
      "[Parsed_subtitles_0 @ 000001caedd8b540] Shaper: FriBidi 1.0.14 (SIMPLE) HarfBuzz-ng 8.5.0 (COMPLEX)\n",
      "[Parsed_subtitles_0 @ 000001caedd8b540] Using font provider directwrite (with GDI)\n",
      "[Parsed_subtitles_0 @ 000001caedd8b540] fontselect: (Arial, 400, 0) -> ArialMT, 0, ArialMT\n",
      "[libx264 @ 000001caedd449c0] using SAR=1/1\n",
      "[libx264 @ 000001caedd449c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 000001caedd449c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 000001caedd449c0] 264 - core 164 r3191 4613ac3 - H.264/MPEG-4 AVC codec - Copyleft 2003-2024 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output/video/post-video9-subtitled.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 91 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "frame=  159 fps=0.0 q=29.0 size=       0KiB time=00:00:05.23 bitrate=   0.1kbits/s speed=9.97x    \n",
      "frame=  480 fps=461 q=29.0 size=       0KiB time=00:00:15.93 bitrate=   0.0kbits/s speed=15.3x    \n",
      "frame=  791 fps=511 q=29.0 size=     256KiB time=00:00:26.30 bitrate=  79.8kbits/s speed=  17x    \n",
      "[out#0/mp4 @ 000001caedcf1740] video:84KiB audio:337KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 5.900203%\n",
      "frame=  900 fps=539 q=-1.0 Lsize=     445KiB time=00:00:29.93 bitrate= 121.9kbits/s speed=17.9x    \n",
      "[libx264 @ 000001caedd449c0] frame I:5     Avg QP:17.27  size:  9446\n",
      "[libx264 @ 000001caedd449c0] frame P:225   Avg QP:10.33  size:    49\n",
      "[libx264 @ 000001caedd449c0] frame B:670   Avg QP:13.67  size:    40\n",
      "[libx264 @ 000001caedd449c0] consecutive B-frames:  0.7%  0.0%  0.7% 98.7%\n",
      "[libx264 @ 000001caedd449c0] mb I  I16..4: 22.2% 73.2%  4.6%\n",
      "[libx264 @ 000001caedd449c0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  0.0%  0.0%  0.0%  0.0%  0.0%    skip:100.0%\n",
      "[libx264 @ 000001caedd449c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.1%  0.0%  0.0%  direct: 0.0%  skip:99.9%  L0:57.6% L1:42.4% BI: 0.0%\n",
      "[libx264 @ 000001caedd449c0] 8x8 transform intra:73.1% inter:1.2%\n",
      "[libx264 @ 000001caedd449c0] coded y,uvDC,uvAC intra: 2.9% 0.0% 0.0% inter: 0.0% 0.0% 0.0%\n",
      "[libx264 @ 000001caedd449c0] i16 v,h,dc,p: 88%  1% 10%  0%\n",
      "[libx264 @ 000001caedd449c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 49%  2% 48%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 000001caedd449c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 24% 11%  3%  4%  5%  4%  4%  4%\n",
      "[libx264 @ 000001caedd449c0] i8c dc,h,v,p: 100%  0%  0%  0%\n",
      "[libx264 @ 000001caedd449c0] Weighted P-Frames: Y:1.8% UV:0.0%\n",
      "[libx264 @ 000001caedd449c0] ref P L0: 91.5%  0.0%  7.4%  1.1%\n",
      "[libx264 @ 000001caedd449c0] ref B L0: 57.9% 42.1%\n",
      "[libx264 @ 000001caedd449c0] ref B L1: 99.7%  0.3%\n",
      "[libx264 @ 000001caedd449c0] kb/s:22.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_file = 'output/video/post-video9.mp4'\n",
    "output_video_file = 'output/video/post-video9-subtitled.mp4'\n",
    "subtitles_file = 'output/subtitles/subtitles.srt'\n",
    "\n",
    "# Add subtitles to the video\n",
    "add_subtitles_command = [\n",
    "    'ffmpeg',\n",
    "    '-i', video_file,\n",
    "    '-vf', f\"subtitles={subtitles_file}\",\n",
    "    '-c:a', 'copy',\n",
    "    output_video_file\n",
    "]\n",
    "\n",
    "# Run the FFmpeg command to add subtitles\n",
    "try:\n",
    "    add_subtitles_result = subprocess.run(add_subtitles_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(f\"Subtitled video created at {output_video_file}\")\n",
    "    print(add_subtitles_result.stdout)\n",
    "    print(add_subtitles_result.stderr)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred while adding subtitles: {e}\")\n",
    "    print(f\"Stderr: {e.stderr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
